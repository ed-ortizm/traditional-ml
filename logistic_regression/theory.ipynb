{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression**\n",
    "It is a statistical method used for binary classification, although it can be extended to multi-class problems as well. It predicts the probability that a given instance belongs to a particular category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main characteristics of logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Binary Outcome**: In the binary classification scenario, it predicts the probability $P(Y=1)$ where $Y$ is the binary response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Sigmoid Function**: The core of logistic regression is the sigmoid (or logistic) function, which is given by:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "The sigmoid function maps any input value $z$ to an output between 0 and 1, making it suitable for probability estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Linear Combination**: In logistic regression, we first compute a linear combination of the input features $X$ and the weights $w$ (including a bias term $b$):\n",
    "\n",
    "$$ z = w_1x_1 + w_2x_2 + ... + w_nx_n + b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Log Odds**: The logistic regression model actually models the log-odds of the probability of the positive class:\n",
    "\n",
    "$$ \\log \\left( \\frac{P(Y=1)}{P(Y=0)} \\right) = w_1x_1 + w_2x_2 + ... + w_nx_n + b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Estimation**: We use the method of Maximum Likelihood Estimation (MLE) to estimate the weights $ w $ that maximize the likelihood of observing the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Prediction**: To make a prediction for a new instance, you:\n",
    "   - Compute the linear combination of its features with the weights.\n",
    "   - Apply the sigmoid function to get the probability $ p $ of the instance belonging to the positive class.\n",
    "   - Classify the instance as positive if $ p $ is greater than a threshold (commonly 0.5) or negative otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Advantages**:\n",
    "   - Outputs have a probabilistic interpretation.\n",
    "   - Can be regularized to avoid overfitting.\n",
    "   - Computationally efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Limitations**:\n",
    "   - Assumes a linear decision boundary.\n",
    "   - Can struggle with non-linear relationships unless feature engineering is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
